# https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installation-guide
# The following steps can be used to setup NVIDIA Container Toolkit on Ubuntu LTS (18.04, 20.04, and 22.04) and Debian (Stretch, Buster) distributions.

# Setting up NVIDIA Container Toolkit
# Setup the package repository and the GPG key:
#
# distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
#       && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
#       && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
#             sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
#             sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

- name: set variables
  set_fact:
    gpg_path: /etc/apt/trusted.gpg.d/nvidia-docker.gpg
    arch: ubuntu18.04

- name: Add nvidia-container-toolkit’s official GPG key
  shell: "curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | gpg --dearmor -o {{gpg_path}}"
  args:
    creates: "{{gpg_path}}"
  become: yes


# Note that in some cases the downloaded list file may contain URLs that do not seem to match the expected value of distribution which is expected as packages may be used for all compatible distributions. As an examples:
#
# For distribution values of ubuntu20.04 or ubuntu22.04 the file will contain ubuntu18.04 URLs
#
# For a distribution value of debian11 the file will contain debian10 URLs
- name: add nvidia-container-toolkit source
  lineinfile:
    regexp: nvidia.github.io
    line: "deb [arch={{cpu_arch}} signed-by={{gpg_path}}] https://nvidia.github.io/libnvidia-container/stable/{{arch}}/{{cpu_arch}} /"
    dest: /etc/apt/sources.list.d/nvidia-docker.list
    create: yes
  become: yes

# Note
#
# If running apt update after configuring repositories raises an error regarding a conflict in the Signed-By option, see the relevant troubleshooting section.
#
# Install the nvidia-container-toolkit package (and dependencies) after updating the package listing:
#
# sudo apt-get update
# sudo apt-get install -y nvidia-container-toolkit
- name: install nvidia-container-toolkit
  apt:
    pkg:
      - nvidia-container-toolkit
  become: true
  register: install

# Configure the Docker daemon to recognize the NVIDIA Container Runtime:
# sudo nvidia-ctk runtime configure --runtime=docker
- name: Configure the Docker daemon to recognize the NVIDIA Container Runtime
  shell: nvidia-ctk runtime configure --runtime=docker
  when: install.changed
  become: true
# Restart the Docker daemon to complete the installation after setting the default runtime:
#
# sudo systemctl restart docker
- name: restart docker daemon
  shell: systemctl restart docker
  when: install.changed
  become: true
# At this point, a working setup can be tested by running a base CUDA container:
#
# sudo docker run --rm --runtime=nvidia --gpus all nvidia/cuda:11.6.2-base-ubuntu20.04 nvidia-smi
# This should result in a console output shown below:
#
# +-----------------------------------------------------------------------------+
# | NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |
# |-------------------------------+----------------------+----------------------+
# | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
# | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
# |                               |                      |               MIG M. |
# |===============================+======================+======================|
# |   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |
# | N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |
# |                               |                      |                  N/A |
# +-------------------------------+----------------------+----------------------+
#
# +-----------------------------------------------------------------------------+
# | Processes:                                                                  |
# |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
# |        ID   ID                                                   Usage      |
# |=============================================================================|
# |  No running processes found                                                 |
# +-----------------------------------------------------------------------------+
